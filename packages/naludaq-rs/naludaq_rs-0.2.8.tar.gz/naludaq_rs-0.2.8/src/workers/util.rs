//! Internal utilities for workers
//!
//!
//! The [`WorkerResponseHandler`] is a utility for safe communication between the control
//! and implementation layers.

use std::fmt::Debug;
use std::sync::atomic::AtomicUsize;
use std::sync::Arc;
use std::time::Duration;
use std::{collections::HashMap, sync::atomic::Ordering};

use flume::{Receiver, Sender};
use tokio::sync::RwLock;

use crate::constants::WORKER_IMPL_REQUEST_TIMEOUT;

/// Utility for tracking requests and responses sent between the control and implementation layers.
/// This type should be used to assure the requests and responses are correctly matched.
#[derive(Debug, Clone)]
pub struct WorkerResponseHandler<C, R> {
    /// Storage for responses pulled from concurrent channel readers
    responses: Arc<RwLock<HashMap<usize, R>>>,
    /// Sender side for sending commands to the worker implementation layer
    tx: Sender<WorkerCommand<C>>,
    /// Receiver side for receiving responses from the worker implementation layer
    rx: Receiver<WorkerResponse<R>>,
    /// Maximum duration to wait for a response.
    timeout: Duration,
}

impl<C, R> WorkerResponseHandler<C, R> {
    /// Create a new [`ResponseHandler`] with the given [`Sender`] and [`Receiver`].
    pub fn new(tx: Sender<WorkerCommand<C>>, rx: Receiver<WorkerResponse<R>>) -> Self {
        Self {
            responses: Arc::new(RwLock::new(HashMap::new())),
            tx,
            rx,
            timeout: WORKER_IMPL_REQUEST_TIMEOUT,
        }
    }

    /// The timeout for requests
    #[allow(unused)]
    pub fn timeout(&self) -> &Duration {
        &self.timeout
    }

    /// Set the timeout for requests.
    #[allow(unused)]
    pub fn set_timeout(&mut self, timeout: Duration) {
        self.timeout = timeout;
    }

    /// Send the command to the worker implementation layer and wait for the response.
    pub async fn request(&self, command: C) -> Option<R> {
        let id = self.next_id();
        let send_fut = self.tx.send_async(WorkerCommand(id, command));
        match send_fut.await {
            Ok(_) => self.try_receive(id).await,
            Err(_) => None,
        }
    }

    /// Wait for a response with the given ID.
    ///
    /// Returns `None` if the timeout is reached.
    async fn try_receive(&self, id: usize) -> Option<R> {
        let fut = async {
            loop {
                // check if answer was inserted by a parallel call to this function
                match self.existing_response(id).await {
                    Some(answer) => break answer,
                    None => (),
                }

                match self.pull_next(id).await {
                    Some(answer) => break answer,
                    None => (),
                }
            }
        };
        tokio::time::timeout(self.timeout.clone(), fut).await.ok()
    }

    /// Check if an answer with the given ID is already stored in the internal [`HashMap`].
    /// If so, it is removed and returned.
    async fn existing_response(&self, id: usize) -> Option<R> {
        if self.responses.read().await.contains_key(&id) {
            self.responses.write().await.remove(&id)
        } else {
            None
        }
    }

    /// Pull the next answer from the channel.
    /// If the answer has the correct ID, it is returned.
    /// Otherwise, it is stored in the internal [`HashMap`] and `None` is returned.
    async fn pull_next(&self, id: usize) -> Option<R> {
        // do not use recv_async here, since it will wait even if the answer
        // has already been received by a concurrent call to this function
        match self.rx.try_recv() {
            Ok(response) => {
                let (recv_id, response) = response.unwrap();
                if recv_id == id {
                    Some(response)
                } else {
                    self.responses.write().await.insert(recv_id, response);
                    None
                }
            }
            Err(_) => None,
        }
    }

    /// Generate the next command ID.
    ///
    /// The ID is generated by atomically incrementing a global counter.
    fn next_id(&self) -> usize {
        static CURRENT_ID: AtomicUsize = AtomicUsize::new(0);

        // This operation wraps to zero on overflow, which is fine for our purposes.
        CURRENT_ID.fetch_add(1, Ordering::Relaxed)
    }
}

/// Wrapper around a command type `C` that includes an ID.
pub struct WorkerCommand<C>(pub usize, pub C);

impl<C> WorkerCommand<C> {
    /// Get the ID of the command.
    #[allow(unused)]
    pub fn id(&self) -> usize {
        self.0
    }

    /// Get the command.
    #[allow(unused)]
    pub fn command(&self) -> &C {
        &self.1
    }

    /// Consume `self` and return the ID and command.
    #[allow(unused)]
    pub fn unwrap(self) -> (usize, C) {
        (self.0, self.1)
    }
}

/// Wrapper around a response type `R` that includes the ID of the command that
/// generated the response.
pub struct WorkerResponse<R>(pub usize, pub R);

impl<R> WorkerResponse<R> {
    /// Get the ID of the command that generated the response.
    #[allow(unused)]
    pub fn id(&self) -> usize {
        self.0
    }

    /// Get the response.
    #[allow(unused)]
    pub fn response(&self) -> &R {
        &self.1
    }

    /// Consume `self` and return the ID and response.
    #[allow(unused)]
    pub fn unwrap(self) -> (usize, R) {
        (self.0, self.1)
    }
}
