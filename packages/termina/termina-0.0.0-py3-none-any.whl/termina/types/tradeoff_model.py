# This file was auto-generated by Fern from our API Definition.

import datetime as dt
import typing

from ..core.datetime_utils import serialize_datetime
from ..core.pydantic_utilities import deep_union_pydantic_dicts, pydantic_v1
from .area import Area
from .scale import Scale


class TradeoffModel(pydantic_v1.BaseModel):
    scale: Scale = pydantic_v1.Field()
    """
    Describes the revenue range of the data whose points represent the trade off.
    """

    raw_data: typing.List[typing.Dict[str, float]] = pydantic_v1.Field()
    """
    Raw data points used to generate the scaling model. Dictionary of the two metrics, x then y.
    """

    discarded_raw_data: typing.List[typing.Dict[str, float]] = pydantic_v1.Field()
    """
    Additional raw data points which were not used in the model fit due to oulier status. Dictionary of the two metrics, x then y.
    """

    areas: typing.List[Area] = pydantic_v1.Field()
    """
    Areas representing the range of the scaling model. The x-y coordinates describe a surface containing 1 - alpha share of the data points.
    """

    def json(self, **kwargs: typing.Any) -> str:
        kwargs_with_defaults: typing.Any = {"by_alias": True, "exclude_unset": True, **kwargs}
        return super().json(**kwargs_with_defaults)

    def dict(self, **kwargs: typing.Any) -> typing.Dict[str, typing.Any]:
        kwargs_with_defaults_exclude_unset: typing.Any = {"by_alias": True, "exclude_unset": True, **kwargs}
        kwargs_with_defaults_exclude_none: typing.Any = {"by_alias": True, "exclude_none": True, **kwargs}

        return deep_union_pydantic_dicts(
            super().dict(**kwargs_with_defaults_exclude_unset), super().dict(**kwargs_with_defaults_exclude_none)
        )

    class Config:
        frozen = True
        smart_union = True
        extra = pydantic_v1.Extra.allow
        json_encoders = {dt.datetime: serialize_datetime}
