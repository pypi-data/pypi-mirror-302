# -*- coding: utf-8 -*-
from setuptools import setup

packages = \
['turbo_alignment',
 'turbo_alignment.cherry_picks',
 'turbo_alignment.cli',
 'turbo_alignment.common',
 'turbo_alignment.common.data',
 'turbo_alignment.common.data.multimodal',
 'turbo_alignment.common.data.multimodal.audio',
 'turbo_alignment.common.data.multimodal.image',
 'turbo_alignment.common.logging',
 'turbo_alignment.common.registry',
 'turbo_alignment.common.s3',
 'turbo_alignment.common.tf',
 'turbo_alignment.common.tf.callbacks',
 'turbo_alignment.common.tf.loaders',
 'turbo_alignment.common.tf.loaders.model',
 'turbo_alignment.dataset',
 'turbo_alignment.dataset.base',
 'turbo_alignment.dataset.chat',
 'turbo_alignment.dataset.classification',
 'turbo_alignment.dataset.ddpo',
 'turbo_alignment.dataset.kto',
 'turbo_alignment.dataset.multimodal',
 'turbo_alignment.dataset.pair_preferences',
 'turbo_alignment.dataset.sampling',
 'turbo_alignment.generators',
 'turbo_alignment.metrics',
 'turbo_alignment.modeling',
 'turbo_alignment.modeling.common',
 'turbo_alignment.modeling.imagebind',
 'turbo_alignment.modeling.imagebind.heads',
 'turbo_alignment.modeling.imagebind.postprocessors',
 'turbo_alignment.modeling.imagebind.preprocessors',
 'turbo_alignment.modeling.imagebind.trunks',
 'turbo_alignment.modeling.liger_kernels',
 'turbo_alignment.modeling.multimodal',
 'turbo_alignment.modeling.multimodal.encoders',
 'turbo_alignment.modeling.multimodal.encoders.audio',
 'turbo_alignment.modeling.multimodal.encoders.image',
 'turbo_alignment.modeling.multimodal.lm',
 'turbo_alignment.modeling.multimodal.projectors',
 'turbo_alignment.modeling.rag',
 'turbo_alignment.pipelines',
 'turbo_alignment.pipelines.inference',
 'turbo_alignment.pipelines.mixin',
 'turbo_alignment.pipelines.preprocessing',
 'turbo_alignment.pipelines.sampling',
 'turbo_alignment.pipelines.train',
 'turbo_alignment.settings',
 'turbo_alignment.settings.datasets',
 'turbo_alignment.settings.generators',
 'turbo_alignment.settings.generators.outputs',
 'turbo_alignment.settings.logging',
 'turbo_alignment.settings.pipelines',
 'turbo_alignment.settings.pipelines.common',
 'turbo_alignment.settings.pipelines.inference',
 'turbo_alignment.settings.pipelines.sampling',
 'turbo_alignment.settings.pipelines.train',
 'turbo_alignment.settings.tf',
 'turbo_alignment.trainers']

package_data = \
{'': ['*']}

install_requires = \
['albumentations>=1.3.1,<2.0.0',
 'bitsandbytes>=0.41.1,<0.42.0',
 'cached-path>=1.6.3,<2.0.0',
 'clearml>=1.16.4,<2.0.0',
 'datasets>=2.18.0,<3.0.0',
 'einops>=0.6.1,<0.7.0',
 'evaluate>=0.4.1,<0.5.0',
 'ftfy>=6.1.1,<7.0.0',
 'hvac>=1.1.1,<2.0.0',
 'iopath>=0.1.10,<0.2.0',
 'jupyter>=1.0.0,<2.0.0',
 'langchain-huggingface>=0.0.3,<0.0.4',
 'loguru>=0.7.0,<0.8.0',
 'numpy>=1.21,<2.0',
 'opencv-python>=4.10.0.84,<5.0.0.0',
 'peft==0.8.2',
 'platformdirs>=3.5.3,<4.0.0',
 'protobuf>=3.20.0,<4.0.0',
 'pydantic-settings>=2.2.1,<3.0.0',
 'pydantic>=2.7.0,<3.0.0',
 'python-dotenv>=1.0.0,<2.0.0',
 'pytorchvideo>=0.1.5,<0.2.0',
 'rouge-score>=0.1.2,<0.2.0',
 'scipy>=1.1.0,<2.0.0',
 'sentence-transformers>=2.2.2,<3.0.0',
 'sentencepiece>=0.1.99,<0.2.0',
 'soundfile>=0.12.1,<0.13.0',
 'timm>=0.9.7,<0.10.0',
 'tomlkit>=0.11.8,<0.12.0',
 'torch==2.3.1',
 'torchaudio>=2.0.2,<3.0.0',
 'transformers==4.43.1',
 'typer>=0.9.0,<0.10.0',
 'wandb>=0.15.3,<0.16.0',
 'wheel>=0.42.0,<0.43.0']

extras_require = \
{'deepspeed': ['deepspeed==0.12', 'accelerate==0.29.0'],
 'gpu': ['faiss-gpu>=1.7.2,<2.0.0', 'vllm==0.5.3']}

setup_kwargs = {
    'name': 'turbo-alignment',
    'version': '0.0.4',
    'description': 'turbo-alignment repository',
    'long_description': '# ğŸš€ Turbo-Alignment\n> Library for industrial alignment.\n\n\n## Table of Contents\n- [What is Turbo-Alignment?](#-what-is-turbo-alignment)\n- [Key Features](#-key-features)\n- [Supported Methods](#-supported-methods)\n- [Implemented metrics](#-implemented-metrics)\n- [How to Use](#-how-to-use)\n- [Installation](#-installation)\n- [Development](#-development)\n- [Library Roadmap](#-library-roadmap)\n- [FAQ](#-faq)\n- [License](#-license)\n\n<a name="-what-is-turbo-alignment"></a>\n## ğŸŒŸ What is Turbo-Alignment?\n\nTurbo-Alignment is a library designed to streamline the fine-tuning and alignment of large language models, leveraging advanced techniques to enhance efficiency and scalability.\n\n<a name="-key-features"></a>\n## âœ¨ Key Features\n\n- **ğŸ“Š Comprehensive Metrics and Logging**: Includes a wide range of metrics such as self-bleu, KL divergence, diversity, etc. all supported out of the box.\n- **ğŸ› ï¸ Streamlined Method Deployment**: Simplifies the process of deploying new methods, allowing for quick development and integration of new datasets and trainers into your pipelines.\n- **ğŸ“š Ready-to-Use Examples**: Convenient examples with configurations and instructions for basic tasks.\n- **âš¡ Fast Inference**: Optimized for quick inference using vLLM.\n- **ğŸ”„ End-to-End Pipelines**: From data preprocessing to model alignment.\n- **ğŸŒ Multimodal Capabilities**: Extensive support for various multimodal functions like Vision Language Modeling.\n- **ğŸ” RAG Pipeline**: Unique pipeline for end2end retrieval-augmented generation training.\n\n<a name="-supported-methods"></a>\n## ğŸ› ï¸ Supported Methods\n\n\nTurbo-Alignment supports a wide range of methods for model training and alignment, including:\n- **ğŸ¯** Supervised Fine-Tuning (SFT)\n- **ğŸ†** Reward Modeling (RM)\n- **ğŸ‘** Direct Preference Optimization (DPO)\n- **ğŸ§ ** Kahneman & Tversky Optimization (KTO) Paired/Unpaired\n- **ğŸ”„** Contrastive Preference Optimization (CPO)\n- **ğŸ­** Identity Preference Optimisation (IPO)\n- **ğŸŒŸ** Sequence Likelihood Calibration with Human Feedback (SLiC-HF)\n- **ğŸ“Š** Statistical Rejection Sampling Optimization (RSO)\n- **ğŸŒ** Vision Language Modeling using MLP from (LLaVA) or C-Abstractor from (HoneyBee) trainable projection model\n- **ğŸ—‚ï¸** Retrieval-Augmented Generation (RAG)\n\n<a name="-implemented-metrics"></a>\n## ğŸ§® Implemented Metrics\n- **ğŸ” ** Distinctness\n- **ğŸŒˆ** Diversity\n- **ğŸ”µ** Self-BLEU\n- **â—** KL-divergence\n- **ğŸ†** Reward\n- **ğŸ“** Length\n- **ğŸŒ€** Perplexity\n- **ğŸŒŸ** METEOR\n- **ğŸ”** Retrieval Utility\n\n<a name="-how-to-use"></a>\n## ğŸ¤– How to Use\n\nTurbo-Alignment offers an intuitive interface for training and aligning large language models. Refer to the detailed examples and configuration files in the documentation to get started quickly with your specific use case. User-friendly guid available [here](docs/GUIDE.md).\n\nThe most crucial aspect is to prepare the dataset in the required format, after which the pipeline will handle everything automatically.\nExamples of datasets are available [here](docs/dataset_example.md).\n\n## Table of use-cases\n- [Training](#-train)\n  - [Supervised Fine-Tuning](#-sft-train)\n  - [Preference Tuning](#-preftune-train)\n    - [Reward Modeling](#-rm-train)\n    - [DPO, CPO, IPO, KTO (Paired)](#-dpo-train)\n    - [KTO (Unpaired)](#-kto-train)\n  - [Multimodal](#-multimodal-train)\n  - [RAG](#-rag-train)\n- [Inference](#-inference)\n  - [Supervised Fine-Tuning](#-sft-inference)\n  - [Multimodal](#-multimodal-inference)\n  - [RAG](#-rag-inference)\n- [Sampling](#-sampling)\n  - [Random](#-random-sampling)\n  - [RM](#-rm-sampling)\n  - [RSO](#-RSO-sampling)\n- [Common](#-common)\n  - [Preprocess](#-preprocess-common)\n  - [Merge adapters to base](#-merge-adapters-to-base-common)\n\n<a name="-train"></a>\n# Train\n\n<a name="-sft-train"></a>\n## Supervised Fine-Tuning\n- **ğŸ“š Dataset type** prepare your dataset  in the `ChatDataset`, examples available [here](docs/dataset_example.md#-chat-dataset) format.\n- **ğŸ“ Configs Example**: [sft.json](configs/exp/train/sft/sft.json)\n- **ğŸ–¥ï¸ CLI launch command**\n```bash\npython -m turbo_alignment train_sft --experiment_settings_path configs/exp/train/sft/sft.json\n```\n<a name="-preftune-train"></a>\n## Preference Tuning\n<a name="-rm-train"></a>\n### Reward Modeling\n- **ğŸ“š Dataset type** prepare your dataset  in the `PairPreferencesDataset` format, examples available [here](docs/dataset_example.md#-pair-preferences)\n- **ğŸ“ Configs Example**: [rm.json](configs/exp/train/rm/rm.json)\n- **ğŸ–¥ï¸ CLI launch command**\n```bash\npython -m turbo_alignment train_rm --experiment_settings_path configs/exp/train/rm/rm.json\n```\n\n<a name="-dpo-train"></a>\n### DPO, IPO, CPO, KTO (Paired)\n- **ğŸ“š Dataset type** prepare your dataset in the `PairPreferencesDataset` format, examples available [here](docs/dataset_example.md#pair-preferences)\n- **ğŸ“ Configs Example**: [dpo.json](configs/exp/train/dpo/dpo.json)\n- **ğŸ–¥ï¸ CLI launch command**\n```bash\npython -m turbo_alignment train_dpo --experiment_settings_path configs/exp/train/dpo/dpo.json\n```\n\n<a name="-kto-train"></a>\n### KTO (Unpaired)\n- **ğŸ“š Dataset type** prepare your dataset in the `KTODataset` format, examples available [here](docs/dataset_example.md#-kto-dataset)\n- **ğŸ“ Configs Examples**: [kto.json](configs/exp/train/kto/kto.json)\n- **ğŸ–¥ï¸ CLI launch command**\n```bash\npython -m turbo_alignment train_kto --experiment_settings_path configs/exp/train/kto/kto.json\n```\n\n<a name="-multimodal-train"></a>\n## Multimodal train\nâŒ›ï¸  in progress..\n\n\n<a name="-rag-train"></a>\n## RAG (Retrieval-Augmented Generation) \n<a name="-sft-rag-train"></a>\n### SFT-RAG\n- **ğŸ“š Dataset type**: prepare your dataset in `ChatDataset`, examples available [here](docs/dataset_example.md#-chat-dataset) format.\n- **ğŸ“ Configs Example**: [sft_with_retrieval_utility](configs/exp/train/sft/llama/sft_with_retrieval_utility.json)\n- **ğŸ–¥ï¸ CLI launch command**: \n```bash\npython -m turbo_alignment train_sft --experiment_settings_path configs/exp/train/sft/llama/sft_with_retrieval_utility.json\n```\n<a name="-e2e-rag-train"></a>\n### End2End-RAG\n- **ğŸ“š Dataset type**: prepare your dataset in `ChatDataset`, examples available [here](docs/dataset_example.md#-chat-dataset) format.\n- **ğŸ“ Configs Example**: [end2end_rag](configs/exp/train/rag/end2end_rag.json)\n- **ğŸ–¥ï¸ CLI launch command**:\n```bash\npython -m turbo_alignment train_rag --experiment_settings_path configs/exp/train/rag/end2end_rag.json\n```\n\n<a name="-inference"></a>\n# Inference\n<a name="-chat-inference"></a>\n## Chat Inference\n- **ğŸ“š Dataset type** prepare your dataset  in the `ChatDataset`, examples available [here](docs/dataset_example.md#-chat-dataset) format.\n- **ğŸ“ Configs Example**: [sft.json](configs/exp/inference/generation/default_llama_adapter.json)\n- **ğŸ–¥ï¸ CLI launch command**\n```bash\npython -m turbo_alignment inference_chat --inference_settings_path configs/exp/inference/generation/default_llama_adapter.json\n```\n\n<a name="-classification-inference"></a>\n## Classification Inference\n- **ğŸ“š Dataset type** prepare your dataset  in the `ClassificationDataset`, examples available [here](docs/dataset_example.md#-classification-dataset) format.\n- **ğŸ“ Configs Example**: [classification_inference.json](configs/exp/inference/classification/classification_inference.json)\n- **ğŸ–¥ï¸ CLI launch command**\n```bash\npython -m turbo_alignment inference_classification --inference_settings_path configs/exp/train/sft/sft.json\n```\n\n<a name="-multimodal-inference"></a>\n## Multimodal Inference\n- **ğŸ“š Dataset type** prepare your dataset  in the `MultimodalDataset`, examples available [here](docs/dataset_example.md#-multimodal-dataset) format.\n- **ğŸ“ Configs Example**: [mlp.json](configs/exp/inference/multimodal/mlp.json)\n- **ğŸ–¥ï¸ CLI launch command**\n```bash\npython -m turbo_alignment inference_multimodal --inference_settings_path configs/exp/inference/multimodal/mlp.json\n```\n\n<a name="-rag-inference"></a>\n## RAG Inference\n- **ğŸ“š Dataset type** prepare your dataset  in the `ChatDataset`, examples available [here](docs/dataset_example.md#-chat-dataset) format.\n- **ğŸ“ Configs Example**: [rag_inference.json](configs/exp/inference/rag/rag_inference.json)\n- **ğŸ–¥ï¸ CLI launch command**\n```bash\npython -m turbo_alignment inference_rag --inference_settings_path configs/exp/inference/rag/rag_inference.json\n```\n\n<a name="-sampling"></a>\n# Sampling\n<a name="-random-sampling"></a>\n## Random Sampling\n- **ğŸ“š Dataset type** prepare your dataset  in the `SamplingRMDataset`, examples available [here](docs/dataset_example.md#-sampling-dataset) format.\n- **ğŸ“ Configs Example**: [random.json](tests/fixtures/configs/sampling/base.json)\n- **ğŸ–¥ï¸ CLI launch command**\n```bash\npython -m turbo_alignment random_sample --experiment_settings_path tests/fixtures/configs/sampling/base.json\n```\n\n<a name="-rso-sampling"></a>\n## RSO Sampling\n- **ğŸ“š Dataset type** prepare your dataset  in the `SamplingRMDataset`, examples available [here](docs/dataset_example.md#-sampling-dataset) format.\n- **ğŸ“ Configs Example**: [rso.json](tests/fixtures/configs/sampling/rso.json)\n- **ğŸ–¥ï¸ CLI launch command**\n```bash\npython -m turbo_alignment rso_sample --experiment_settings_path tests/fixtures/configs/sampling/rso.json\n```\n\n<a name="-rm-sampling"></a>\n## Reward Model Sampling\n- **ğŸ“š Dataset type** prepare your dataset  in the `SamplingRMDataset`, examples available [here](docs/dataset_example.md#-sampling-dataset) format.\n- **ğŸ“ Configs Example**: [rm.json](tests/fixtures/configs/sampling/rm.json)\n- **ğŸ–¥ï¸ CLI launch command**\n```bash\npython -m turbo_alignment rm_sample --experiment_settings_path tests/fixtures/configs/sampling/rm.json\n```\n\n<a name="-common"></a>\n# Common\n<a name="-merge_adapters_to_base"></a>\n## Merge Adapters to base model\n- **ğŸ“ Configs Example**: [llama.json](configs/utils/merge_adapters_to_base/llama.json)\n- **ğŸ–¥ï¸ CLI launch command**\n```bash\npython -m turbo_alignment merge_adapters_to_base --settings_path configs/utils/merge_adapters_to_base/llama.json\n```\n\n<a name="-preprocess_multimodal_dataset"></a>\n## Preprocess Multimodal Dataset\n- **ğŸ“ Configs Example**: [coco2014_clip.json](configs/utils/preprocess/coco2014_clip.json)\n- **ğŸ–¥ï¸ CLI launch command**\n```bash\npython -m turbo_alignment preprocess_multimodal_dataset --settings_path configs/utils/preprocess/coco2014_clip.json\n```\n\n\n<a name="-installation"></a>\n## ğŸš€ Installation\n\n### ğŸ“¦ Python Package\n```bash\npip install turbo-alignment\n```\n\n### ğŸ› ï¸ From Source\nFor the latest features before an official release:\n```bash\npip install git+https://github.com/turbo-llm/turbo-alignment.git\n```\n\n### ğŸ“‚ Repository\nClone the repository for access to examples:\n```bash\ngit clone https://github.com/turbo-llm/turbo-alignment.git\n```\n\n<a name="-development"></a>\n## ğŸŒ± Development\n\nContributions are welcome! Read the [contribution guide](https://github.com/turbo-llm/turbo-alignment/blob/main/CONTRIBUTING.md) and set up the development environment:\n```bash\ngit clone https://github.com/turbo-llm/turbo-alignment.git\ncd turbo-alignment\npoetry install\n```\n\n<a name="-library-roadmap"></a>\n## ğŸ“ Library Roadmap\n\n- Increasing number of tutorials\n- Enhancing test coverage\n- Implementation of Online RL methods like PPO and Reinforce\n- Facilitating distributed training\n- Incorporating low-memory training approaches\n\n\n## â“ FAQ\n### How do I install Turbo-Alignment?\nSee the [Installation](#-installation) section for detailed instructions.\n\n### Where can I find docs?\nGuides and docs are available [here](docs/GUIDE.md).\n\n### Where can I find tutorials?\nTutorials are available [here](tutorials/tutorial.md).\n\n\n## ğŸ“ License\nThis project is licensed, see the [LICENSE](https://github.com/turbo-llm/turbo-alignment/-/blob/main/LICENSE) file for details.\n\n\n## References\n\n- DPO Trainer implementation inspired by Leandro von Werra et al. (2020) TRL: Transformer Reinforcement Learning. GitHub repository, GitHub. Available at: [https://github.com/huggingface/trl](https://github.com/huggingface/trl).\n\n- Registry implementation inspired by Matt Gardner, Joel Grus, Mark Neumann, Oyvind Tafjord, Pradeep Dasigi, Nelson F. Liu, Matthew Peters, Michael Schmitz, and Luke S. Zettlemoyer. 2017. AllenNLP: A Deep Semantic Natural Language Processing Platform. Available at: [arXiv:1803.07640](https://arxiv.org/abs/1803.07640).\n\n- Liger Kernels implementation inspired by Hsu, Pin-Lun, Dai, Yun, Kothapalli, Vignesh, Song, Qingquan, Tang, Shao, and Zhu, Siyu, 2024. Liger-Kernel: Efficient Triton Kernels for LLM Training. Available at: [https://github.com/linkedin/Liger-Kernel](https://github.com/linkedin/Liger-Kernel).\n',
    'author': 'T Mega Alignment Team',
    'author_email': 'n.surnachev@tcsbank.ru',
    'maintainer': 'None',
    'maintainer_email': 'None',
    'url': 'https://github.com/turbo-llm/turbo-alignment',
    'packages': packages,
    'package_data': package_data,
    'install_requires': install_requires,
    'extras_require': extras_require,
    'python_requires': '>=3.10,<4.0',
}


setup(**setup_kwargs)
