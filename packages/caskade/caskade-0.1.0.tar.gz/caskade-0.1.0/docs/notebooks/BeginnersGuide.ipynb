{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beginners Guide to `caskade`\n",
    "\n",
    "Here we will introduce all of the relevant concepts and capabilities of `caskade` and how to build numerical simulators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from caskade import Module, Param, forward, LiveParam\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Template\n",
    "\n",
    "All `caskade` simulators follow the same basic template. Certain ingredients are always involved:\n",
    "\n",
    "- Subclass the `Module` object\n",
    "- Call the `super().__init__()` at the top\n",
    "- Create some `Param` attributes\n",
    "- Decorate a function with `@forward`\n",
    "- Include some of the params (by attribute name) as keyword arguments\n",
    "\n",
    "You can also provide a name for the `Module`, though this is optional. If not given, then a unique name will be made from the class name and a counter of the form `ClassName_i`. Note that for both the `__init__` and `@forward` methods you may have any other positional parameters or keyword parameters you like, they will not interfere. Keep in mind that for the `@forward` method when requesting a `Param` value, you must set it as a keyword argument, usually just by defaulting to `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyFirstSim(Module):\n",
    "    def __init__(self, name, a=None, b=None, c_shape=()):\n",
    "        super().__init__(name) # optional name for the module\n",
    "        self.a = Param(\"a\", a) # standard parameter\n",
    "        self.b = Param(\"b param\", b) # note name can be anything we want\n",
    "        self.c = Param(\"c\", None, c_shape) # Here we only provide a shape, not a value\n",
    "\n",
    "    @forward\n",
    "    def myfunction(self, x, a=None, b=None, c=None, d = 1):\n",
    "        return x * a + b + c + d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may now create instances of this class, which let us set parameters in the init. We can print the object to see a dictionary which shows the graph structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myfirstname|module\n",
      "    a|dynamic\n",
      "    b param|dynamic\n",
      "    c|dynamic\n"
     ]
    }
   ],
   "source": [
    "firstsim = MyFirstSim(\"myfirstname\", c_shape=(2, 2))\n",
    "print(firstsim) # show the graph which is just three dynamic parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can build our list of parameters and pass them to the function as the last positional argument (or a few other ways)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6., 7.],\n",
      "        [8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "#                      a                  b                    c\n",
    "params = [torch.tensor(1.0), torch.tensor(2.0), torch.tensor([[1.0, 2.0], [3.0, 4.0]])]\n",
    "print(firstsim.myfunction(1.0, params, d = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different ways to pass the parameters\n",
    "\n",
    "Let's explore a few different ways that one can pass the parameters into a `caskade` forward method. First, we can change what the `params` construct looks like depending on what is convenient for our purposes. A list is nice since we can break up the list into more manageable chunks (such as one list for the parameters in a given module) then just add the lists together later to make the `params` object. A single flattened `Tensor` is nice since many other codes (think `scipy.minimize`, `emcee`, etc.) like to work with an input `x` that is just a single vector. A dictionary may be conceptually easier to construct, either alongside building your simulator, or just writing out manually, since it follows the same structure as the simulator graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of tensors:  tensor([[6., 7.],\n",
      "        [8., 9.]])\n",
      "Single flattened tensor:  tensor([[6., 7.],\n",
      "        [8., 9.]])\n",
      "Dictionary of tensors:  tensor([[6., 7.],\n",
      "        [8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "# List of tensors (this is what we did above)\n",
    "params_list = [torch.tensor(1.0), torch.tensor(2.0), torch.tensor([[1.0, 2.0], [3.0, 4.0]])]\n",
    "print(\"List of tensors: \", firstsim.myfunction(1.0, params_list, d = 2))\n",
    "\n",
    "# Single flattened tensor\n",
    "params_tensor = torch.cat([p.flatten() for p in params_list])\n",
    "print(\"Single flattened tensor: \", firstsim.myfunction(1.0, params_tensor, d = 2))\n",
    "\n",
    "# Dictionary of tensors\n",
    "params_dict = {\"a\": torch.tensor(1.0), \"b\": torch.tensor(2.0), \"c\": torch.tensor([[1.0, 2.0], [3.0, 4.0]])}\n",
    "print(\"Dictionary of tensors: \", firstsim.myfunction(1.0, params_dict, d = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, once we have the `params` there are a couple ways we can get it into the forward method. So far we have just been setting the last positional argument as the params, but we can also pass it as a keyword, or if the parameters aren't going to change very much we can set them as static."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last positional argument:  tensor([[6., 7.],\n",
      "        [8., 9.]])\n",
      "Keyword argument:  tensor([[6., 7.],\n",
      "        [8., 9.]])\n",
      "Set parameters as static:  tensor([[6., 7.],\n",
      "        [8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "# Pass as last positional argument\n",
    "print(\"Last positional argument: \", firstsim.myfunction(1.0, params_list, d = 2))\n",
    "\n",
    "# Pass as keyword argument\n",
    "print(\"Keyword argument: \", firstsim.myfunction(1.0, params=params_list, d = 2))\n",
    "\n",
    "# Set parameters as static\n",
    "firstsim.a = params_list[0]\n",
    "firstsim.b = params_list[1]\n",
    "firstsim.c = params_list[2]\n",
    "print(\"Set parameters as static: \", firstsim.myfunction(1.0, d = 2))\n",
    "# Set them back to dynamic\n",
    "firstsim.a = None\n",
    "firstsim.b = None\n",
    "firstsim.c = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different types of parameters\n",
    "\n",
    "So far we have only looked at `dynamic` and `static` parameters. `caskade` allows users to build complex simulators with relationships between parameters. Next lets see all the different types: \n",
    "\n",
    "- `dynamic` is given as input when calling a `@forward` method\n",
    "- `static` is a fixed value\n",
    "- `pointer` returns the value from a different `Param`\n",
    "- `function` is computed from other `Param` values\n",
    "- `live` is expected to be filled during the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pointer parameter:  tensor([[5., 6.],\n",
      "        [7., 8.]])\n",
      "Function parameter:  tensor([[6., 7.],\n",
      "        [8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "# Make a pointer parameter\n",
    "firstsim.b = firstsim.a\n",
    "params_dict = {\"a\": torch.tensor(1.0), \"c\": torch.tensor([[1.0, 2.0], [3.0, 4.0]])} # note no \"b\"\n",
    "print(\"Pointer parameter: \", firstsim.myfunction(1.0, params_dict, d = 2))\n",
    "\n",
    "# Make a function parameter\n",
    "firstsim.b = lambda x: x.children[\"a link\"].value * 2\n",
    "firstsim.b.link(\"a link\", firstsim.a) # have to manually link the parameter\n",
    "print(\"Function parameter: \", firstsim.myfunction(1.0, params_dict, d = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `live` parameter is a bit more involved and will take some planning. We need a simulator that will fill the value of the live parameter during runtime. Lets make a new class to see what that looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LiveParamTestSim(Module):\n",
    "    def __init__(self, a=None):\n",
    "        super().__init__()\n",
    "        self.a = Param(\"a\", a)\n",
    "        self.b = Param(\"b\", LiveParam)\n",
    "        self.c = 3.0\n",
    "\n",
    "    @forward\n",
    "    def mylivefunction(self, x, a=None, b=None):\n",
    "        if b.value is LiveParam:\n",
    "            b.value = a * 2 + x + self.c\n",
    "        return a + b.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see how the param `b` can be updated during runtime, possibly from another `Param`, or possibly from other inputs to the function, or from instance variables. Once the value for `b` has been set, any further calculations can use it even if they are in other functions, or other `Module`s (with pointing parameters or by multiple links to the same `Module`). Note as well that by checking `if b.value is LiveParam:` we can ensure that even if `mylivefunction` is called multiple times, the value for `b` will only be filled once per simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Live parameter: tensor(8.)\n"
     ]
    }
   ],
   "source": [
    "livesim = LiveParamTestSim()\n",
    "params = {\"a\": torch.tensor(1.0)}\n",
    "print(\"Live parameter:\", livesim.mylivefunction(torch.tensor(2.0), params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nesting Modules\n",
    "\n",
    "Thus far we have only worked with simulators that are a single `Module`, while the capability of `caskade` is nice at this level it is somewhat overkill for such a scenario as you could just manually make the forward method work the way you like. The real power of `caskade` comes from nesting `Module` objects to build complex scientific simulators, all while keeping the flexible and robust interfaces seen above. Here we will see what is possible with nesting, although the parameter side of things should all be very familiar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMainSim(Module):\n",
    "    def __init__(self, a_utility, b_action, c_param=None):\n",
    "        super().__init__()\n",
    "        self.a_utility = a_utility # This will hold a module\n",
    "        self.b_action = b_action # this is a list of modules, so we have to link them manually\n",
    "        for sim in self.b_action:\n",
    "            self.link(sim.name, sim)\n",
    "        self.c_param = Param(\"c\", c_param) # regular parameter\n",
    "        self.d_param = Param(\"d\", LiveParam) # live parameter\n",
    "\n",
    "    @forward\n",
    "    def mymainfunction(self, x, c_param=None, d_param=None): # note we use the attribute name, not the parameter name\n",
    "        u = self.a_utility.myutilityfunction(x+2)\n",
    "        if d_param.value is LiveParam:\n",
    "            d_param.value = x + u\n",
    "        s = self.mysecondfunction(u)\n",
    "        for sim in self.b_action:\n",
    "            s = s + sim.myactionfunction(s)\n",
    "        return s * c_param\n",
    "    \n",
    "    @forward\n",
    "    def mysecondfunction(self, y, d_param=None):\n",
    "        u = self.a_utility.myutilityfunction(y+2)\n",
    "        if d_param.value is LiveParam: # creates a default value if d_param isn't set\n",
    "            d_param.value = 0\n",
    "        return u + y + d_param.value\n",
    "    \n",
    "class MyActionSim(Module):\n",
    "    def __init__(self, a_utility, a=None, b=None):\n",
    "        super().__init__()\n",
    "        self.a_utility = a_utility # same module as in MyMainSim\n",
    "        self.a = Param(\"a\", a)\n",
    "        self.b = Param(\"b\", b)\n",
    "\n",
    "    @forward\n",
    "    def myactionfunction(self, w, a=None, b=None):\n",
    "        u = self.a_utility.myutilityfunction(w+3)\n",
    "        return u * a + b\n",
    "    \n",
    "class MyUtilitySim(Module):\n",
    "    def __init__(self, u=None):\n",
    "        super().__init__()\n",
    "        self.u = Param(\"u\", u)\n",
    "\n",
    "    @forward\n",
    "    def myutilityfunction(self, z, u=None):\n",
    "        return u * z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see a number of ways that `Module`s may be combined. The `MyUtilitySim` module is used in both `MyMainSim` and `MyActionSim`. We will make multiple instances of `MyActionSim` which will all get linked to `MyMainSim`. The module `MyMainSim` has two `@forward` methods, the second one `mysecondfunction` uses the result of a `LiveParam` which is computed midway through the `mymainfunction`. Note as well that `mysecondfunction` only uses the `d` parameter, and doesn't use `c` even though it could in principle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyMainSim|module\n",
      "    MyUtilitySim|module\n",
      "        u|dynamic\n",
      "    MyActionSim|module\n",
      "        MyUtilitySim|module\n",
      "            u|dynamic\n",
      "        a|dynamic\n",
      "        b|dynamic\n",
      "    MyActionSim_0|module\n",
      "        MyUtilitySim|module\n",
      "            u|dynamic\n",
      "        a|dynamic\n",
      "        b|dynamic\n",
      "    MyActionSim_1|module\n",
      "        MyUtilitySim|module\n",
      "            u|dynamic\n",
      "        a|dynamic\n",
      "        b|dynamic\n",
      "    c|dynamic\n",
      "    d|live\n",
      "number of parameters:  8\n",
      "mymainfunction result:  tensor(306.)\n",
      "mysecondfunction result:  tensor(4.)\n"
     ]
    }
   ],
   "source": [
    "util = MyUtilitySim()\n",
    "#                      u for MyUtilitySim\n",
    "params = [torch.tensor(1.0)]\n",
    "actions = []\n",
    "for i in range(3):\n",
    "    actions.append(MyActionSim(util))\n",
    "    #                     a for MyActionSim, b for MyActionSim\n",
    "    params = params + [torch.tensor(i), torch.tensor(i+1)]\n",
    "\n",
    "main = MyMainSim(util, actions)\n",
    "#                      c for MyMainSim\n",
    "params = params + [torch.tensor(3.0)]\n",
    "print(main) # show the graph which is a bit more complex now\n",
    "print(\"number of parameters: \", len(params))\n",
    "\n",
    "print(\"mymainfunction result: \", main.mymainfunction(1.0, params))\n",
    "print(\"mysecondfunction result: \", main.mysecondfunction(1.0, params)) # called with same params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interacting with PyTorch\n",
    "\n",
    "The above `list` version of `params` is very convenient since we could build it alongside building the simulator. The `Tensor` version is also convenient since we can easily use it alongside PyTorch autograd or vmap functionalities. Here we will see how this lets us use PyTorch capabilities. We will also see how we may pass batched parameters into `caskade` simulators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mymainfunction gradient:  tensor([600., 270.,  18., 144.,   9., 102.,   3., 102.])\n",
      "mymainfunction batched:  tensor([306., 378., 450.])\n"
     ]
    }
   ],
   "source": [
    "# Using PyTorch autograd\n",
    "params_tensor = torch.cat(tuple(p.flatten() for p in params)) # flattened vector with shape (8,)\n",
    "print(\"mymainfunction gradient: \", torch.func.grad(main.mymainfunction,argnums=1)(1.0, params_tensor))\n",
    "\n",
    "# Using PyTorch vmap\n",
    "batched_params = torch.stack([params_tensor, params_tensor, params_tensor]) # batched parameters with shape (3, 8)\n",
    "print(\"mymainfunction batched: \", torch.vmap(main.mymainfunction)(torch.tensor([1.0, 2.0, 3.0]), batched_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it is also possible for `Module` objects to accept batched parameters. However, keep in mind that this simply means passing through the parameters normally, except with extra dimensions. You can/will get different behavior than vmap, which is closer to treating the batch dimension as a `for-loop`. This may actually be the desired effect, it's up to you to build the simulator accordingly. To understand what is going on, consider the current simulator, each parameter is a scalar and the batch dimension is `(3,)` so with tuple addition the dimensionality of each parameter becomes `(3,) + () = (3,)`. If instead of scalars, we had set the shapes to all be length 1 vectors `(1,)` then the resulting dimensions as passed through `caskade` would be `(3,) + (1,) = (3,1)` which would behave differently through the simulator as we can see below. We can see that the shape of other input parameters (`x`) also affect the results, as would be expected since the tensor shapes are interacting according to how we built our simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utility u length 1 vector:\n",
      "------------------------\n",
      "mymainfunction internally batched x.shape=(3,):  tensor([[306., 378., 450.],\n",
      "        [306., 378., 450.],\n",
      "        [306., 378., 450.]])\n",
      "mymainfunction internally batched x.shape=(3,1):  tensor([[306., 306., 306.],\n",
      "        [378., 378., 378.],\n",
      "        [450., 450., 450.]])\n",
      "\n",
      "utility u scalar:\n",
      "------------------------\n",
      "mymainfunction internally batched x.shape=(3,):  tensor([306., 378., 450.])\n",
      "mymainfunction internally batched x.shape=(3,1):  tensor([[306., 306., 306.],\n",
      "        [378., 378., 378.],\n",
      "        [450., 450., 450.]])\n"
     ]
    }
   ],
   "source": [
    "main.a_utility.u.shape = (1,) # set as a length 1 vector\n",
    "print(\"utility u length 1 vector:\\n------------------------\")\n",
    "print(\"mymainfunction internally batched x.shape=(3,): \", main.mymainfunction(torch.tensor([1.0, 2.0, 3.0]), batched_params))\n",
    "print(\"mymainfunction internally batched x.shape=(3,1): \", main.mymainfunction(torch.tensor([[1.0], [2.0], [3.0]]), batched_params))\n",
    "print()\n",
    "main.a_utility.u.shape = () # set as a scalar (like everything else)\n",
    "print(\"utility u scalar:\\n------------------------\")\n",
    "print(\"mymainfunction internally batched x.shape=(3,): \", main.mymainfunction(torch.tensor([1.0, 2.0, 3.0]), batched_params))\n",
    "print(\"mymainfunction internally batched x.shape=(3,1): \", main.mymainfunction(torch.tensor([[1.0], [2.0], [3.0]]), batched_params))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want only one parameter to be batched? Or what about two parameters having different batch dimensions? Well in this case it is not possible build a single `Tensor` to encapsulate this capability since a tensor must have a shape like `(int1, int2, int3, ...)`. However, this is not a restriction for the `list` or `dict` inputs to a `caskade` simulator! Simply set the elements however you like, just take note that it's up to you to build the simulator accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mymainfunction funky:  tensor([[[  558.,  4350., 18522.],\n",
      "         [  306.,  1515.,  4746.],\n",
      "         [   54., -1320., -9030.]],\n",
      "\n",
      "        [[  612.,  4485., 18774.],\n",
      "         [  360.,  1650.,  4998.],\n",
      "         [  108., -1185., -8778.]],\n",
      "\n",
      "        [[  666.,  4620., 19026.],\n",
      "         [  414.,  1785.,  5250.],\n",
      "         [  162., -1050., -8526.]]])\n"
     ]
    }
   ],
   "source": [
    "params_funky = params\n",
    "params_funky[0] = torch.tensor([1.0, 2.0, 3.0]) # shape (3,)\n",
    "params_funky[1] = torch.tensor([[1.0], [0.0], [-1.0]]) # shape (3, 1)\n",
    "params_funky[2] = torch.arange(9).reshape((3,3,1)) # shape (3, 3, 1)\n",
    "# now the first three parameters are funky shapes with params_funky[2] even having a different set of batch dimensions\n",
    "print(\"mymainfunction funky: \", main.mymainfunction(1.0, params_funky))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we're done! Those are all the elemental abilities of `caskade`, I hope that by this point you have a sense of the vast possibilities of simulators that can be constructed. Happy science-ing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PY39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
