{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67c54b8b",
   "metadata": {},
   "source": [
    "# Forecaster and MVForecaster Attributes\n",
    "\n",
    "- You can look up what metrics and estimators are available for you to use by initiating a `Forecaster` or `MVForecaster` instance and checking the object's attributes. This notebook shows how to do that with `Forecaster` only, but the same attributes exist in `MVForecaster`, unless specified otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b442bcb-5060-489d-bece-fd077f564c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scalecast.Forecaster import Forecaster\n",
    "from scalecast.MVForecaster import MVForecaster\n",
    "\n",
    "f = Forecaster(\n",
    "    y = [1,2,3,4], # required\n",
    "    current_dates = ['2021-01-01','2021-02-01','2021-03-01','2021-04-01'], # required, can be a numbered index if dates not known/needed\n",
    "    future_dates = None, # optional. this accepts an int type that counts the forecast horizon steps. future dates can be generated after the object is initiated.\n",
    "    test_length = 0, # default is 0, but this accepts int or float types to determine the number/fraction of obs to hold out for model testing\n",
    "    cis = False, # default is False, change to True if you want confidence intervals. requires a test set.\n",
    "    metrics = [\n",
    "        'rmse', # default\n",
    "        'mape', # default\n",
    "        'mae', # default\n",
    "        'r2', # default\n",
    "        'smape',\n",
    "        'mse',\n",
    "        'abias',\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343236a8",
   "metadata": {},
   "source": [
    "## `Forecaster.estimators`\n",
    "- These are the the models that forecast and can be set by using `f.set_estimator(...)`.\n",
    "- They come from popular machine learning libraries like scikit-learn, keras, statsmodels, and others.\n",
    "- More estimators can be added, assuming they follow a basic sklearn API, by using the `Forecaster.add_sklearn_estimator()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0caf64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catboost\n",
      "elasticnet\n",
      "gbt\n",
      "knn\n",
      "lasso\n",
      "lightgbm\n",
      "mlp\n",
      "mlr\n",
      "rf\n",
      "ridge\n",
      "sgd\n",
      "svr\n",
      "xgboost\n",
      "arima\n",
      "hwes\n",
      "prophet\n",
      "silverkite\n",
      "rnn\n",
      "lstm\n",
      "naive\n",
      "tbats\n",
      "theta\n",
      "combo\n"
     ]
    }
   ],
   "source": [
    "print(*f.estimators,sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dbb4b1",
   "metadata": {},
   "source": [
    "### `Forecaster.can_be_tuned`\n",
    "- The following estimators can be tuned using a grid search and cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "261769c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catboost\n",
      "elasticnet\n",
      "gbt\n",
      "knn\n",
      "lasso\n",
      "lightgbm\n",
      "mlp\n",
      "mlr\n",
      "rf\n",
      "ridge\n",
      "sgd\n",
      "svr\n",
      "xgboost\n",
      "arima\n",
      "hwes\n",
      "prophet\n",
      "silverkite\n",
      "rnn\n",
      "lstm\n",
      "naive\n",
      "tbats\n",
      "theta\n"
     ]
    }
   ],
   "source": [
    "print(*f.can_be_tuned,sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6d5f50-832f-452a-99e2-f6ecceb8d174",
   "metadata": {},
   "source": [
    "As of version 0.18.0, the only model missing here is combo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d33c34",
   "metadata": {},
   "source": [
    "### `Forecaster.sklearn_estimators`\n",
    "- These all come from scikit-learn or use a basic scikit-learn API and behave similarly, including accepting a `normalizer` argument, accepting an `Xvars` argument, and offering any recursive evaluation length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17368c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catboost\n",
      "elasticnet\n",
      "gbt\n",
      "knn\n",
      "lasso\n",
      "lightgbm\n",
      "mlp\n",
      "mlr\n",
      "rf\n",
      "ridge\n",
      "sgd\n",
      "svr\n",
      "xgboost\n"
     ]
    }
   ],
   "source": [
    "print(*f.sklearn_estimators,sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431b6ff5",
   "metadata": {},
   "source": [
    "- Add any other sklearn estimator to the `Forecaster` ([docs](https://scalecast.readthedocs.io/en/latest/Forecaster/Forecaster.html#src.scalecast.Forecaster.Forecaster.add_sklearn_estimator)) and `MVForecaster` ([docs](https://scalecast.readthedocs.io/en/latest/Forecaster/MVForecaster.html#src.scalecast.MVForecaster.MVForecaster.add_sklearn_estimator)) classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c9927d",
   "metadata": {},
   "source": [
    "## `Forecaster.metrics`\n",
    "- These are all the metrics available for use when optimizing models.\n",
    "- All metrics from the [metrics class](https://scalecast.readthedocs.io/en/latest/Forecaster/Util.html#metrics) that accept only two arguments are available and can be passed when initiating the object or later using `Forecaster.set_metrics()`.\n",
    "- Custom metrics and metric functions also accepted, as long as they only take two arguments (array of actuals and array of forecasted values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58e6e57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse\n",
      "mape\n",
      "mae\n",
      "r2\n",
      "smape\n",
      "mse\n",
      "abias\n"
     ]
    }
   ],
   "source": [
    "print(*f.metrics.keys(),sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef0abfa",
   "metadata": {},
   "source": [
    "## `Forecaster.determine_best_by`\n",
    "- These are generated from the metrics in `Forecaster.metrics` and include in-sample, test-set, and validation-set metrics.\n",
    "- Many functions can monitor one of these metrics when applying auto ML methods.\n",
    "- Plots and dataframe exports can be ordered best-to-worst according to any of these.\n",
    "- The difference between 'Level' and non-level only comes into play if `Forecaster.diff()` has been called to difference a series. However, `SeriesTransformer` also differences series, in addition to being able to take more dynamic transformations, making the need to use `Forecaster.diff()` irrelevant. It will soon go away and there will be no distinction between level and non-level metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61da8d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestSetRMSE\n",
      "TestSetMAPE\n",
      "TestSetMAE\n",
      "TestSetR2\n",
      "TestSetSMAPE\n",
      "TestSetMSE\n",
      "TestSetABIAS\n",
      "InSampleRMSE\n",
      "InSampleMAPE\n",
      "InSampleMAE\n",
      "InSampleR2\n",
      "InSampleSMAPE\n",
      "InSampleMSE\n",
      "InSampleABIAS\n",
      "ValidationMetricValue\n"
     ]
    }
   ],
   "source": [
    "print(*f.determine_best_by,sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dd2a79",
   "metadata": {},
   "source": [
    "## `Forecaster.normalizer`\n",
    "- These are all the options to scale your data when using an sklearn estimator.\n",
    "- All models receive a MinMax scale by default (since it is highly encouraged to always use scaled data for some scikit-learn models), but None is also available as an argument to avoid scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "905f8843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minmax\n",
      "normalize\n",
      "scale\n",
      "robust\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(*f.normalizer.keys(),sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9794b0f4",
   "metadata": {},
   "source": [
    "## `MVForecaster.optimizer_funcs`\n",
    "- These are the functions you can use to optimize models in `MVForecaster` only.\n",
    "- This means that if you use the `\"mean\"` option, which is the object's default, when tuning models, it will choose the best one based on which metric had the best average performance on all series\n",
    "- You can add your own functions by calling `add_optimizer_func()`: see the [docs](https://scalecast.readthedocs.io/en/latest/Forecaster/MVForecaster.html#src.scalecast.MVForecaster.MVForecaster.add_optimizer_func)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d65a1c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean\n",
      "min\n",
      "max\n"
     ]
    }
   ],
   "source": [
    "mvf = MVForecaster(f, f.copy())\n",
    "print(*mvf.optimizer_funcs.keys(),sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999239e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
