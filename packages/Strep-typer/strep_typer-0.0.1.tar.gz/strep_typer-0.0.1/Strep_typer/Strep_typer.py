# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/02_generic_analysis.ipynb.

# %% auto 0
__all__ = ['report_missing_arguments', 'check_arguments', 'sample_data', 'folder_parser', 'unit_test_1', 'cli']

# %% ../nbs/02_generic_analysis.ipynb 2
# That export there, it makes sure this code goes into the module.

# standard libs
import os
import re

# Common to template
# add into settings.ini, requirements, package name is python-dotenv, for conda build ensure `conda config --add channels conda-forge`
import dotenv  # for loading config from .env files, https://pypi.org/project/python-dotenv/
import envyaml  # Allows to loads env vars into a yaml file, https://github.com/thesimj/envyaml
import fastcore  # To add functionality related to nbdev development, https://github.com/fastai/fastcore/
from fastcore import (
    test,
)
from fastcore.script import (
    call_parse,
)  # for @call_parse, https://fastcore.fast.ai/script
import json  # for nicely printing json and yaml
from fastcore import test
from fastcore.script import call_parse
from Strep_typer import (
    core,
)
from pathlib import Path  # to be able write :Path in cli function

# Project specific libraries
import sqlite3
import smtplib
from email.message import EmailMessage

# %% ../nbs/02_generic_analysis.ipynb 5
def report_missing_arguments(input, config_file):
    # Check if an input-file is provided, either as argument or unit-test. If not, exit with error
    if input is None and config_file is None:
        print(
            "ERROR: Input log-file is missing. Provide it as input argument or config-file"
        )
        exit()

# %% ../nbs/02_generic_analysis.ipynb 7
def check_arguments(input, config_file):
    exit_code = 0
    error_messages = list()
    # If a config-file was provided, check that it exists. If not, exit directly.
    if config_file is not None:
        config_dir = os.path.abspath(config_file)
        isConfig = os.path.isfile(config_dir)
        if not isConfig:
            print("ERROR: The provided config-file doesnt exist: " + config_dir)
            exit()
    input_dir = os.path.abspath(input)
    isInput = os.path.isfile(input_dir)
    if not isInput:
        error_msg = "Your input log-file does not exist: " + input_dir
        error_messages.append(error_msg)
        exit_code = 1
    # Report errors and exit (if any)
    if exit_code == 1:
        print("Error: there were problems with the following script arguments:")
        for msg in error_messages:
            print(msg)
        exit()

# %% ../nbs/02_generic_analysis.ipynb 9
class sample_data:
    def __init__(self, attributes):
        try:
            self.sample_name = attributes["sample_name"]
        except KeyError:
            self.sample_name = False
        try:
            self.assembly_file = attributes["assembly_file"]
        except KeyError:
            self.assembly_file = False
        try:
            self.r1_file = attributes["r1_file"]
        except KeyError:
            self.r1_file = False
        try:
            self.r2_file = attributes["r2_file"]
        except KeyError:
            self.r2_file = False
        try:
            self.r_Nanopore_file = attributes["r_Nanopore_file"]
        except KeyError:
            self.r_Nanopore_file = False
        try:
            self.metadata = attributes["metadata"]
        except KeyError:
            self.metadata = {}


class folder_parser:
    def __init__(self, input_folder, regex_patterns):
        input_folder = os.path.abspath(input_folder)
        Illumina_r1_files = {}
        Illumina_r2_files = {}
        Nanopore_r_files = {}
        assembly_files = {}
        files = os.listdir(input_folder)
        for file in files:
            if file.endswith((".tsv", ".txt", ".tab")):
                metadata_file = os.path.join(input_folder, file)
                metadata = read_metadata(metadata_file)
            elif file.endswith((".fa", ".fasta", ".fna")):
                sample_name = re.match(
                    r"(?P<sample_name>.+?)(\.fa|\.fna|\.fasta)", file
                ).group("sample_name")
                try:
                    assembly_files[sample_name].append(file)
                except KeyError:
                    assembly_files[sample_name] = [file]
            elif file.endswith(".fastq.gz"):
                re_match = re.match(
                    r"(?P<sample_name>.+?)(?P<sample_number>(_S[0-9]+)?)(?P<lane>(_L[0-9]+)?)_(?P<paired_read_number>R[1|2])(?P<set_number>(_[0-9]+)?)(?P<file_extension>\.fastq\.gz)",
                    file,
                )
                sample_name = re_match.group("sample_name")
                read_number = re_match.group("paired_read_number")
                if read_number == "R1":
                    try:
                        Illumina_r1_files[sample_name].append(file)
                    except KeyError:
                        Illumina_r1_files[sample_name] = [file]
                elif read_number == "R2":
                    try:
                        Illumina_r2_files[sample_name].append(file)
                    except KeyError:
                        Illumina_r2_files[sample_name] = [file]

# %% ../nbs/02_generic_analysis.ipynb 16
def unit_test_1(test_log_file):
    transfers = log_parser(test_log_file)
    print(transfers)
    print("\n".join(transfers.transfer_errors))
    assert (
        len(transfers.transfer_instances) == 8
    )  # log contains 7 non-empty transfer instances
    assert (
        transfers.succesful_transfers == 5
    )  # log contains 5 succesful transfer instances
    assert transfers.failed_transfers == 3  # log contains 2 failed transfer instances
    assert (
        transfers.transfer_instances[0].timestamp == "2024/06/14 09:44:55"
    )  # First instance should match first instance in log file
    assert (
        sorted(transfers.transfer_instances)[0].timestamp == "2024/06/13 12:27:09"
    )  # After sorting, first instance should be earliest timestamp
    assert (
        len(transfers.transfer_errors) == 5
    )  ## There should be three total transfer errors recorded

# %% ../nbs/02_generic_analysis.ipynb 18
@call_parse
def cli(
    # Definition of command-line arguments
    input: str = None,  # Path to log-file from rclone (required, unless using config)
    config_file: str = None,  # Config-file containing all required arguments (required, unless using input arg)
    unit_test: bool = False,  # Run unit-test on log-file in repo (optional)
) -> None:
    # Set env vars and get config variables
    config = core.get_config(config_file)
    # If unit-test requested: run unit-test and exit
    if unit_test:
        if config_file is not None:
            print(
                "ERROR: Unit-test requested together with config-file argument, which could interfere with the test! Exiting!"
            )
            exit()
        print("Unit-test requested. Will do unit-test and exit when done")
        unit_test_1(config["rclone_log_parser"]["input_test"]["test_file"])
        exit()
    # Overwrite input default values in config-file if the user has provided command-line arguments
    if input is not None:
        config["rclone_log_parser"]["input"]["log_file"] = input
    # Check if any required arguments are missing
    report_missing_arguments(input, config_file)
    # Check validity of arguments
    check_arguments(config["rclone_log_parser"]["input"]["log_file"], config_file)
    # Run commands
    transfers = log_parser(
        config["rclone_log_parser"]["input"]["log_file"]
    )  # class object, containing various info on transfer(s) parsed from logfile
    print(transfers)
    # Possible next: print some summary information to stdout about transfers found? Not sure if that is necessary in production.
    # Next: write function that adds data into transfer-db
