Metadata-Version: 2.1
Name: llm-tasker
Version: 0.1.2
Summary: A lightweight Python library for creating tasks and workflows with Large Language Models (LLMs) using prompt templates.
Home-page: https://github.com/nikirg/llm_task
License: MIT
Author: Nikita Irgashev
Author-email: nik.irg@yandex.ru
Requires-Python: >=3.11,<4.0
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.11
Requires-Dist: openai (>=1.51.0,<2.0.0)
Requires-Dist: pydantic (>=2.9.2,<3.0.0)
Project-URL: Documentation, https://github.com/nikirg/llm_task
Project-URL: Repository, https://github.com/nikirg/llm_task
Description-Content-Type: text/markdown

# LLM Tasker

**LLM Tasker** is a small Python library designed to simplify working with language models and prompts. It provides a structure for defining tasks, configuring LLM clients, and managing responses in a type-safe manner. 

## Features

- Supports various LLM clients (e.g., OpenAI) with easy configuration.
- Define structured prompt-based tasks as Python classes.
- Type-safe implementation using Pydantic models.
- Asynchronous support for efficient interaction with LLM services.
- Reusable task configuration and logic.


## Installation

```bash
pip install llm_tasker
```

## Example Usage
```python
from openai import AsyncOpenAI
from pydantic import BaseModel
from llm_tasker.task import LLMTask, TaskConfig

LLM_API_KEY = "your-openai-api-key"
LLM_MODEL_ID = "gpt-4o
client = AsyncOpenAI(api_key=LLM_API_KEY)

class AnalysisResult(BaseModel):
    subject: str
    verb: str
    object: str

class NestedOutputTask(LLMTask):
    """
    Analyze the following sentence and return a structured nested output with the main subject, verb, and object.
    
    Sentence: `{sentence}`

    Output format:
    ```json
    {{
        "subject": "subject of the sentence",
        "verb": "main verb",
        "object": "object of the sentence"
    }}
    ```
    """
    
    sentence: str
    result: AnalysisResult | None = None
    config = TaskConfig(client=client, model=LLM_MODEL_ID)

if __name__ == "__main__":
    import asyncio

    async def main():
        task = NestedOutputTask(
            sentence="The cat chased the mouse."
        )
        await task()
        print(task.result)

    asyncio.run(main())
```

## License

This project is licensed under the MIT License.

