is_train: false
num_steps: 3
runtime:
  all_reduce_alg: null
  batchnorm_spatial_persistent: false
  dataset_num_private_threads: null
  default_shard_dim: -1
  distribution_strategy: mirrored
  enable_xla: false
  gpu_thread_mode: null
  loss_scale: null
  mixed_precision_dtype: null
  num_cores_per_replica: 1
  num_gpus: 0
  num_packs: 1
  per_gpu_thread_count: 0
  run_eagerly: false
  task_index: -1
  tpu: null
  tpu_enable_xla_dynamic_padder: null
  use_tpu_mp_strategy: false
  worker_hosts: null
task:
  allow_image_summary: false
  differential_privacy_config: null
  init_checkpoint: ''
  model:
    cls_heads: [{activation: tanh, cls_token_idx: 0, dropout_rate: 0.1, inner_dim: 768,
        name: next_sentence, num_classes: 2}]
    encoder:
      bert:
        attention_dropout_rate: 0.1
        dropout_rate: 0.1
        embedding_size: null
        hidden_activation: gelu
        hidden_size: 360
        initializer_range: 0.02
        intermediate_size: 3072
        max_position_embeddings: 512
        norm_first: false
        num_attention_heads: 12
        num_layers: 13
        output_range: null
        return_all_encoder_outputs: false
        return_attention_scores: false
        return_word_embeddings: false
        type_vocab_size: 2
        vocab_size: 30522
      type: bert
    mlm_activation: gelu
    mlm_initializer_range: 0.02
    mlm_output_weights_use_proj: false
  name: natural_language_processing
  scale_loss: false
  train_data:
    apply_tf_data_service_before_batching: false
    autotune_algorithm: null
    block_length: 1
    cache: false
    cycle_length: null
    deterministic: null
    doc_batch_size: 8
    drop_remainder: true
    enable_shared_tf_data_service_between_parallel_trainers: false
    enable_tf_data_service: false
    file_type: tfrecord
    global_batch_size: 8
    input_path: ''
    is_training: true
    masking_rate: 0.15
    max_predictions_per_seq: 19
    prefetch_buffer_size: null
    ram_budget: null
    seed: null
    seq_length: 8
    sharding: true
    shuffle_buffer_size: 100
    text_field_names: [text]
    tf_data_service_address: null
    tf_data_service_job_name: null
    tfds_as_supervised: false
    tfds_data_dir: ''
    tfds_name: wikipedia/20201201.en
    tfds_skip_decoding_feature: ''
    tfds_split: train
    trainer_id: null
    use_next_sentence_label: true
    use_whole_word_masking: false
    vocab_file_path: ./data/vocab.txt
  validation_data: null
trainer:
  allow_tpu_summary: false
  best_checkpoint_eval_metric: ''
  best_checkpoint_export_subdir: ''
  best_checkpoint_metric_comp: higher
  checkpoint_interval: 1000
  continuous_eval_timeout: 3600
  eval_tf_function: true
  eval_tf_while_loop: false
  loss_upper_bound: 1000000.0
  max_to_keep: 5
  optimizer_config:
    ema: null
    learning_rate:
      polynomial:
        cycle: false
        decay_steps: null
        end_learning_rate: 0.0
        initial_learning_rate: 0.0001
        name: PolynomialDecay
        offset: 0
        power: 1.0
      type: polynomial
    optimizer:
      adamw:
        amsgrad: false
        beta_1: 0.9
        beta_2: 0.999
        clipnorm: null
        clipvalue: null
        epsilon: 1.0e-07
        exclude_from_weight_decay: [LayerNorm, layer_norm, bias]
        global_clipnorm: null
        gradient_clip_norm: 1.0
        include_in_weight_decay: null
        name: AdamWeightDecay
        weight_decay_rate: 0.01
      type: adamw
    warmup:
      polynomial:
        name: polynomial
        power: 1
        warmup_steps: null
      type: polynomial
  preemption_on_demand_checkpoint: true
  recovery_begin_steps: 0
  recovery_max_trials: 0
  steps_per_loop: 1000
  summary_interval: 1000
  train_steps: 1000000
  train_tf_function: true
  train_tf_while_loop: true
  validation_interval: 1000
  validation_steps: -1
  validation_summary_subdir: validation
