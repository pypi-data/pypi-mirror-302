_usage_: |
  defaults:
    - CLIPVisionModelTaskPool@: _template
_target_: fusion_bench.taskpool.CLIPVisionModelTaskPool
_version_: "0.2"
_recursive_: false
test_datasets: ??? # The datasets to evaluate the model on
base_model: openai/clip-vit-base-patch32
clip_model:
  _target_: transformers.CLIPModel.from_pretrained
  pretrained_model_name_or_path: ${..base_model} # The base model to use
processor:
  _target_: transformers.CLIPProcessor.from_pretrained
  pretrained_model_name_or_path: ${..base_model} # The base model to use
data_processor: ${.processor}
dataloader_kwargs:
  batch_size: 128
  num_workers: 8
  pin_memory: True
  drop_last: False
  shuffle: False
