{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RayPipeline with detached component actors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you run `RayPipeline` under the hood it creates [ray actors](https://docs.ray.io/en/latest/ray-core/actors.html) for each component in the pipeline (`ComponentActor` instances). \n",
    "`ComponentActor` exposes `run_component` method which can be remotely executed by `RayPipelineProcessor` - another actor which orchestrates pipeline execution logic (e.g. runs components according to the order defined by pipeline connections). Lifetime of Haystack component instance is same as actor's. Please notice each Haystack component might have its own logic which could be not idempotent - we can not control it.\n",
    "\n",
    "In case Haystack component requires `warm_up` - it will perform it during component's first run (first time `run_component` is called). Sometimes `warm_up` might be an expensive operation and ideally we would like to avoid it when we call `run_component` again. Internally ComponentActor will store a flag in case component has already been warmed up so that next time it runs we skip this step.\n",
    "\n",
    "Generally, whenever you run pipeline with `pipeline.run` the following happens:\n",
    "\n",
    "1. Pipeline is validated for correctness, along with given inputs if any\n",
    "2. `RayPipelineProcessor` actor is created\n",
    "3. `ComponentActor` is created for each component in pipeline\n",
    "4. `RayPipelineProcessor` starts pipeline execution\n",
    "5. When pipeline execution finishes all actors will be destroyed by default. Next time you call `pipeline.run` steps will be repeated, so **actor instances will be re-created**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In cases you would like to keep component actors alive between sequential pipeline runs that can be achieved with [Named Actors](https://docs.ray.io/en/latest/ray-core/actors/named-actors.html) and \"detached\" [Actor Lifetimes](https://docs.ray.io/en/latest/ray-core/actors/named-actors.html#actor-lifetimes). `ray-haystack` allows you to control actor names and lifetimes with `RayPipelineSettings`. So in order to reuse actor instances between pipeline runs we could configure actors as \"detached\". Detached actors are not destroyed until manually killed with `ray.kill` or cluster shutdown.\n",
    "\n",
    "Lets explore \"detached\" named component actors in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "pip install \"ray[default]\" # Ray library with dashboard included\n",
    "pip install ray-haystack\n",
    "pip install \"datasets>=2.6.1\" # Required by pipeline\n",
    "pip install \"sentence-transformers>=3.0.0\" # Required by pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a pipeline with default settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup required env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OpenAI API key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start local Ray cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "# Shutdown cluster if any is running at the moment\n",
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare DocumentStore by writing Documents with embeddings.\n",
    "\n",
    "`RayInMemoryDocumentStore` is actually runs within an actor behind the scenes so we could share a single instance of it in Ray cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "from haystack.dataclasses import Document\n",
    "\n",
    "from ray_haystack.utils import RayInMemoryDocumentStore\n",
    "\n",
    "document_store = RayInMemoryDocumentStore()\n",
    "\n",
    "doc_embedder = SentenceTransformersDocumentEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "doc_embedder.warm_up()\n",
    "\n",
    "dataset = load_dataset(\"bilgeyucel/seven-wonders\", split=\"train\")\n",
    "docs = [Document(content=doc[\"content\"], meta=doc[\"meta\"]) for doc in dataset]\n",
    "\n",
    "docs_with_embeddings = doc_embedder.run(docs)\n",
    "document_store.write_documents(docs_with_embeddings[\"documents\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create RayPipeline for basic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.builders.prompt_builder import PromptBuilder\n",
    "from haystack.components.embedders import (\n",
    "    SentenceTransformersTextEmbedder,\n",
    ")\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "\n",
    "from ray_haystack.ray_pipeline import RayPipeline\n",
    "from ray_haystack.utils import RayInMemoryEmbeddingRetriever\n",
    "\n",
    "template = \"\"\"\n",
    "Given the following information, answer the question.\n",
    "\n",
    "Context:\n",
    "{% for document in documents %}\n",
    "    {{ document.content }}\n",
    "{% endfor %}\n",
    "\n",
    "Question: {{question}}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "text_embedder = SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "retriever = RayInMemoryEmbeddingRetriever(document_store) # document_store is created above\n",
    "generator = OpenAIGenerator(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "prompt_builder = PromptBuilder(template=template)\n",
    "\n",
    "basic_rag_pipeline = RayPipeline()\n",
    "\n",
    "basic_rag_pipeline.add_component(\"text_embedder\", text_embedder)\n",
    "basic_rag_pipeline.add_component(\"retriever\", retriever)\n",
    "basic_rag_pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
    "basic_rag_pipeline.add_component(\"llm\", generator)\n",
    "\n",
    "basic_rag_pipeline.connect(\"text_embedder.embedding\", \"retriever.query_embedding\")\n",
    "basic_rag_pipeline.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "basic_rag_pipeline.connect(\"prompt_builder\", \"llm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run pipeline with default settings\n",
    "\n",
    "Note: While pipeline is running navigate to http://127.0.0.1:8265/#/actors to see all actors being created for component execution, and then destroyed when pipeline finishes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What does Rhodes Statue look like?\"\n",
    "\n",
    "basic_rag_pipeline.run({\"text_embedder\": {\"text\": question}, \"prompt_builder\": {\"question\": question}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check if any actor is still available after pipeline finishes execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will result in exception as actor does not exist (in DEAD state)\n",
    "\n",
    "ray.get_actor(name=\"llm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: There could be some delay until actor is actually destroyed by Ray (e.g. have gone out of scope in Python). It could be a problem if you immediately create actor with same name (with \"non_detached\" lifetime) - it will result in error as no actors with same name can exist in same namespace. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline with detached component actors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RayPipeline` can be configured with particular [actor options](https://docs.ray.io/en/latest/ray-core/api/doc/ray.actor.ActorClass.options.html) for all components within the pipeline.\n",
    "\n",
    "So it should be possible to specify the lifetime of actors in case we don't want those to be destroyed when pipeline finishes.\n",
    "\n",
    "Lets create same pipeline using settings to detach component actors and reuse same actor instances next time pipeline runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray_haystack import RayPipelineSettings\n",
    "\n",
    "ray_settings: RayPipelineSettings = {\n",
    "    \"common\": {\n",
    "        \"actor_options\": {\n",
    "            \"lifetime\": \"detached\", # Don't kill the actor after pipeline finishes\n",
    "            \"get_if_exists\": True, # When creating actor get one that already exists (with same name)\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run pipeline with common component actor settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Why did people build Great Pyramid of Giza?\"\n",
    "\n",
    "basic_rag_pipeline.run(\n",
    "    {\"text_embedder\": {\"text\": question}, \"prompt_builder\": {\"question\": question}}, ray_settings=ray_settings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get actor by name, it should be still available in detached state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.get_actor(name=\"llm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets run pipeline once again, it should reuse previously created component actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How did Colossus of Rhodes collapse?\"\n",
    "\n",
    "basic_rag_pipeline.run(\n",
    "    {\"text_embedder\": {\"text\": question}, \"prompt_builder\": {\"question\": question}}, ray_settings=ray_settings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above pipeline execution should reuse component actors, potentially improving performance as there is no additional overhead. It should be quite useful when component needs to \"warm up\" and we would like to avoid repeating this step each time `run` method is called."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on your use case you can setup `RayPipeline` with various actor options during runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Terminate detached actors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to [documentation](https://docs.ray.io/en/latest/ray-core/actors/terminating-actors.html) detached actors must be manually destroyed. \n",
    "\n",
    "So you will need a way to clean up actors so that those do not get stuck running and consuming resources once you no longer need working/running a pipeline.\n",
    "\n",
    "One way to do it is to get actor handle and then use `ray.kill` util to terminate the actor, e.g.\n",
    "\n",
    "```py\n",
    "actor = ray.get_actor(\"component_name\") # Assuming you did not change default name for the actor\n",
    "ray.kill(actor)\n",
    "```\n",
    "\n",
    "Below is a more generic version of actor \"cleanup\" logic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for component_name in basic_rag_pipeline.get_component_names():\n",
    "    ray.kill(ray.get_actor(component_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If actor can not be found by name `ray.get_actor` will raise an error (ValueError). \n",
    "\n",
    "Please also consider cases when you manually provide name for a component actor - in such case you should find the actor by its custom name - not by component name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternatively there is an easy option to kill detached actors:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_rag_pipeline.cleanup() # kill actors belonging to the pipeline which were created as detached"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shutdown Ray cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
